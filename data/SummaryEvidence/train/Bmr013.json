{
    "domain": "Academic(icsi)",
    "ami": {},
    "icsi": {
        "tokenized_answer": [
            "The Berkeley Meeting Recorder group discussed the collection status for a set of connected digits recordings that are nearly complete and ready to be trained on a recognizer.",
            "Anticipated results were discussed in reference to results obtained for other digits corpora, i.e. Aurora and TI-digits.",
            "The group also considered the prospect of performing fine-grained acoustic-phonetic analyses on a subset of Meeting Recorder digits or Switchboard data.",
            "Pre-segmentation manipulations that allow for the segmentation of channel-specific speech/non-speech portions of the signal and the distinction of foreground versus background speech were discussed.",
            "Finally, speaker fe008 and fe016 reported on new efforts to adapt transcriptions to the needs of the SRI recognizer, including conventions for encoding acronyms, numbers, ambient noise, and unidentified inbreaths.",
            "The group decided to delegate the extraction of digits to the transcriber pool.",
            "A tentative decision was also made to delegate transcribers with the task of labelling a subset of digits or Switchboard data for fine-grained acoustic-phonetic features.",
            "Speaker fe008 will run selected Meeting Recorder data through channelize and determine whether the resulting units are of a sufficient length.",
            "With respect to encoding more fine-grained acoustic information in transcriptions, the question was posed: which features should be marked?",
            "Speaker mn014 reported problems pre-segmenting speech recorded via the lapel microphones.",
            "Normalization of the energy measured across and within channels is problematic when performed for speakers who say little or nothing during meetings.",
            "The evaluation of pre-segmented data is difficult without tightly transcribed time references to the individual channels from which the speech was derived.",
            "The SRI recognizer requires that multi-channel format units not be too large, indicating that some additional pre-processing of unit lengths may be necessary.",
            "A test set of Meeting Recorder digits is nearly complete.",
            "Future work will include training this data on a recognizer, and feeding the recognizer with corresponding far-field microphone data.",
            "It was noted that the results of experiments testing similar digits corpora have yielded high error rates, indicating that similar problems may be expected for the set of Meeting Recoreder digits.",
            "The group discussed the prospect of performing fine-grained acoustic-phonetic analyses on a subset of digits or Switchboard data.",
            "It was suggested that prior to the use of data-driven methods, knowledge-driven approaches should be used to 'seed' the data with sub-phonemic features, either manually, or using a rich pronunciation dictionary.",
            "A new version of the pre-segmentation tool that segments channel-specific speech/non-speech portions of the signal has been developed and tested.",
            "Future pre-segmentation work will include normalizing other features, such as loudness, enabling the distinction of foreground versus background speech.",
            "Speaker mn014 will also look at cross-correlations for removing false overlaps.",
            "New efforts were reported to adapt transcriptions to the needs of the SRI recognizer, including conventions for encoding acronyms, numbers, ambient noise, and unidentified inbreaths.",
            "With the arrival of the SRI recognizer, 12 hours of forced aligned, recognized data can be expected."
        ],
        "answer_sentence_index": [
            "Bmr013.s.1",
            "Bmr013.s.2",
            "Bmr013.s.3",
            "Bmr013.s.4",
            "Bmr013.s.5",
            "Bmr013.s.6",
            "Bmr013.s.7",
            "Bmr013.s.8",
            "Bmr013.s.9",
            "Bmr013.s.10",
            "Bmr013.s.11",
            "Bmr013.s.12",
            "Bmr013.s.13",
            "Bmr013.s.14",
            "Bmr013.s.15",
            "Bmr013.s.16",
            "Bmr013.s.17",
            "Bmr013.s.18",
            "Bmr013.s.19",
            "Bmr013.s.20",
            "Bmr013.s.21",
            "Bmr013.s.22",
            "Bmr013.s.23"
        ],
        "evidence": [
            [
                {
                    "type": "CES",
                    "turn_index": 2,
                    "sent_index": 0,
                    "speaker": "Grad F",
                    "content": "Um , so I wanted to discuss digits briefly , but that won't take too long ."
                },
                {
                    "type": "CES",
                    "turn_index": 18,
                    "sent_index": 1,
                    "speaker": "Grad F",
                    "content": "OK well , the , w uh as you can see from the numbers on the digits we 're almost done ."
                },
                {
                    "type": "CES",
                    "turn_index": 18,
                    "sent_index": 7,
                    "speaker": "Grad F",
                    "content": "And so , once we 're {disfmarker} it 's done it would be very nice to train up a recognizer and actually start working with this data ."
                }
            ],
            [
                {
                    "type": "CES",
                    "turn_index": 19,
                    "sent_index": 0,
                    "speaker": "PhD D",
                    "content": "So we 'll have a corpus that 's the size of TI - digits ?"
                },
                {
                    "type": "PES",
                    "turn_index": 20,
                    "sent_index": 1,
                    "speaker": "Grad F",
                    "content": "One particular test set of TI - digits ."
                },
                {
                    "type": "CES",
                    "turn_index": 57,
                    "sent_index": 1,
                    "speaker": "Professor C",
                    "content": "Yeah just by way of uh , uh , a uh , order of magnitude , uh , um , we 've been working with this Aurora , uh data set ."
                },
                {
                    "type": "CES",
                    "turn_index": 57,
                    "sent_index": 2,
                    "speaker": "Professor C",
                    "content": "And , uh , the best score , on the , nicest part of the data , that is , where you 've got training and test set that are basically the same kinds of noise and so forth , uh , is about ,"
                },
                {
                    "type": "CES",
                    "turn_index": 57,
                    "sent_index": 4,
                    "speaker": "Professor C",
                    "content": "I think the best score was something like five percent , uh , error , per digit ."
                }
            ],
            [
                {
                    "type": "PES",
                    "turn_index": 118,
                    "sent_index": 2,
                    "speaker": "Professor C",
                    "content": "One question I have that {disfmarker} that I mean , we wouldn't know the answer to now but might , do some guessing , but I was talking before about doing some model modeling of arti uh , uh , marking of articulatory , features , with overlap and so on ."
                },
                {
                    "type": "CES",
                    "turn_index": 120,
                    "sent_index": 1,
                    "speaker": "Professor C",
                    "content": "On some subset ."
                },
                {
                    "type": "CES",
                    "turn_index": 120,
                    "sent_index": 2,
                    "speaker": "Professor C",
                    "content": "One thought might be to do this uh , on {disfmarker} on the digits , or some piece of the digits ."
                },
                {
                    "type": "CES",
                    "turn_index": 323,
                    "sent_index": 4,
                    "speaker": "Professor C",
                    "content": "So , I mean another way to look at this is to , is to , uh , do some stuff on Switchboard which has all this other , stuff to it ."
                },
                {
                    "type": "PES",
                    "turn_index": 325,
                    "sent_index": 0,
                    "speaker": "Professor C",
                    "content": "And then , um , As we get , further down the road and we can do more things ahead of time , we can , do some of the same things to the meeting data ."
                },
                {
                    "type": "CES",
                    "turn_index": 331,
                    "sent_index": 0,
                    "speaker": "Postdoc B",
                    "content": "They 'd be able to do phonetic - level coding , or articulatory ."
                }
            ],
            [
                {
                    "type": "PES",
                    "turn_index": 359,
                    "sent_index": 0,
                    "speaker": "Professor C",
                    "content": "Uh , new version of , uh , presegmentation ?"
                },
                {
                    "type": "CES",
                    "turn_index": 360,
                    "sent_index": 0,
                    "speaker": "PhD A",
                    "content": "Uh , oh yeah , um , {vocalsound} I worked a little bit on the {disfmarker} on the presegmentation to {disfmarker} to get another version which does channel - specific , uh , speech - nonspeech detection ."
                },
                {
                    "type": "CES",
                    "turn_index": 362,
                    "sent_index": 0,
                    "speaker": "PhD A",
                    "content": "And , and , therefore to be able to , uh , somewhat distinguish between foreground and background speech in {disfmarker} in the different {disfmarker} in {disfmarker} each channel ."
                }
            ],
            [
                {
                    "type": "CES",
                    "turn_index": 539,
                    "sent_index": 1,
                    "speaker": "Postdoc B",
                    "content": "it drifted into the afternoon , {comment} {vocalsound} uh , concerning this issue of , um , the , well there 's basically the issue of the interplay between the transcript format and the processing that , they need to do for , the SRI recognizer ."
                },
                {
                    "type": "CES",
                    "turn_index": 543,
                    "sent_index": 0,
                    "speaker": "Postdoc B",
                    "content": "also we discussed some adaptational things ,"
                },
                {
                    "type": "CES",
                    "turn_index": 547,
                    "sent_index": 0,
                    "speaker": "Postdoc B",
                    "content": "uh {disfmarker} You know I hadn't , uh , incorporated , a convention explicitly to handle acronyms , for example ,"
                },
                {
                    "type": "CES",
                    "turn_index": 549,
                    "sent_index": 6,
                    "speaker": "Postdoc B",
                    "content": "And then , a similar conv uh , convention for numbers ."
                },
                {
                    "type": "PES",
                    "turn_index": 549,
                    "sent_index": 11,
                    "speaker": "Postdoc B",
                    "content": "Or a non - vocal sound like a doors door - slam , and that can be easily done with a , you know , just a {disfmarker} one little additional thing in the , in the general format ."
                },
                {
                    "type": "CES",
                    "turn_index": 558,
                    "sent_index": 2,
                    "speaker": "PhD G",
                    "content": "So if they hear a breath and they don't know who breath it is it 's better to put it in that channel than to put it in the speaker 's channel"
                }
            ],
            [
                {
                    "type": "PES",
                    "turn_index": 37,
                    "sent_index": 0,
                    "speaker": "Grad F",
                    "content": "And so the {disfmarker} the question is , should we have the transcribers do that or should we just do it ?"
                },
                {
                    "type": "PES",
                    "turn_index": 37,
                    "sent_index": 1,
                    "speaker": "Grad F",
                    "content": "Well , some of us ."
                },
                {
                    "type": "PES",
                    "turn_index": 39,
                    "sent_index": 2,
                    "speaker": "Postdoc B",
                    "content": "and I think it 's a {disfmarker} it 's a fine idea partly because , um , it 's not un unrelated to their present skill set ,"
                },
                {
                    "type": "CES",
                    "turn_index": 117,
                    "sent_index": 1,
                    "speaker": "Grad F",
                    "content": "And then , hand off to Jane , and the transcribers to do the actual extraction of the digits ."
                }
            ],
            [
                {
                    "type": "CES",
                    "turn_index": 135,
                    "sent_index": 1,
                    "speaker": "Professor C",
                    "content": "So , may maybe the thing will be do {disfmarker} to take some very small subset , I mean not have a big , program , but take a small set , uh , subset of the conversational speech and a small subset of the digits ,"
                },
                {
                    "type": "CES",
                    "turn_index": 142,
                    "sent_index": 0,
                    "speaker": "PhD D",
                    "content": "Hafta think about , the particular acoustic features to mark , too , because , I mean , some things , they wouldn't be able to mark , like , uh , you know , uh , tense lax ."
                },
                {
                    "type": "CES",
                    "turn_index": 222,
                    "sent_index": 0,
                    "speaker": "PhD D",
                    "content": "So it would be {disfmarker} it would be great if we had , either these kind of , labelings on , the same portion of Switchboard that Steve marked , or , Steve 's type markings on this data , with these ."
                },
                {
                    "type": "CES",
                    "turn_index": 271,
                    "sent_index": 0,
                    "speaker": "PhD D",
                    "content": "Well , you know , um {disfmarker} I mean if we 're talking about , having the , annotators annotate these kinds of features , it seems like ,"
                },
                {
                    "type": "PES",
                    "turn_index": 291,
                    "sent_index": 1,
                    "speaker": "Professor C",
                    "content": "So I mean i we 'll see wha how much we can , uh , get the people to do , and how much money we 'll have and all this sort of thing ,"
                },
                {
                    "type": "CES",
                    "turn_index": 323,
                    "sent_index": 4,
                    "speaker": "Professor C",
                    "content": "So , I mean another way to look at this is to , is to , uh , do some stuff on Switchboard which has all this other , stuff to it ."
                }
            ],
            [
                {
                    "type": "PES",
                    "turn_index": 539,
                    "sent_index": 9,
                    "speaker": "Postdoc B",
                    "content": "And , um , {nonvocalsound} their recognizer would prefer that the units not be overly long ."
                },
                {
                    "type": "CES",
                    "turn_index": 539,
                    "sent_index": 11,
                    "speaker": "Postdoc B",
                    "content": "So , as a first pass through , a first chance without having to do a lot of hand - editing , what we 're gonna do , is , I 'll run it through channelize , give them those data after I 've done the editing process and be sure it 's clean ."
                },
                {
                    "type": "CES",
                    "turn_index": 541,
                    "sent_index": 0,
                    "speaker": "Postdoc B",
                    "content": "And then we 'll see if the units that we 're getting , uh , with the {disfmarker} at that level , are sufficient ."
                }
            ],
            [
                {
                    "type": "CES",
                    "turn_index": 549,
                    "sent_index": 8,
                    "speaker": "Postdoc B",
                    "content": "Um , and also I 'll be , um , encoding , as I do my post - editing , the , things that are in curly brackets , which are clarificational material ."
                },
                {
                    "type": "PES",
                    "turn_index": 550,
                    "sent_index": 0,
                    "speaker": "PhD G",
                    "content": "Yeah we j we just needed a way to , strip , you know , all the comments , all the things th the {disfmarker} that linguist wants but the recognizer can't do anything with ."
                },
                {
                    "type": "CES",
                    "turn_index": 550,
                    "sent_index": 1,
                    "speaker": "PhD G",
                    "content": "Um , but to keep things that we mapped to like reject models , or , you know , uh , mouth noise , or , cough ."
                },
                {
                    "type": "CES",
                    "turn_index": 550,
                    "sent_index": 6,
                    "speaker": "PhD G",
                    "content": "well the {disfmarker} good example was an inbreath , where a transcriber working from , the mixed , signal , doesn't know whose breath it is ,"
                },
                {
                    "type": "CES",
                    "turn_index": 567,
                    "sent_index": 1,
                    "speaker": "Postdoc B",
                    "content": "One question ,"
                },
                {
                    "type": "PES",
                    "turn_index": 567,
                    "sent_index": 2,
                    "speaker": "Postdoc B",
                    "content": "e w would that be a single speaker or is that multiple speakers overlapping ?"
                },
                {
                    "type": "PES",
                    "turn_index": 568,
                    "sent_index": 0,
                    "speaker": "Grad E",
                    "content": "No . No , but if we 're gonna segment it ,"
                },
                {
                    "type": "PES",
                    "turn_index": 576,
                    "sent_index": 0,
                    "speaker": "PhD A",
                    "content": "I {disfmarker} I {disfmarker} I thought that perhaps the transcribers could start then from the {disfmarker} those mult multi - channel , uh , speech - nonspeech detections , if they would like to ."
                },
                {
                    "type": "PES",
                    "turn_index": 577,
                    "sent_index": 0,
                    "speaker": "PhD G",
                    "content": "And I just don't know ,"
                }
            ],
            [
                {
                    "type": "CES",
                    "turn_index": 360,
                    "sent_index": 0,
                    "speaker": "PhD A",
                    "content": "Uh , oh yeah , um , {vocalsound} I worked a little bit on the {disfmarker} on the presegmentation to {disfmarker} to get another version which does channel - specific , uh , speech - nonspeech detection ."
                },
                {
                    "type": "CES",
                    "turn_index": 362,
                    "sent_index": 2,
                    "speaker": "PhD A",
                    "content": "There are some problems with the lapel mike ."
                }
            ],
            [
                {
                    "type": "CES",
                    "turn_index": 360,
                    "sent_index": 1,
                    "speaker": "PhD A",
                    "content": "And , what I did is I used some normalized features which , uh , look in into the {disfmarker} which is normalized energy , uh , energy normalized by the mean over the channels and by the , minimum over the , other ."
                },
                {
                    "type": "CES",
                    "turn_index": 360,
                    "sent_index": 2,
                    "speaker": "PhD A",
                    "content": "within each channel ."
                },
                {
                    "type": "CES",
                    "turn_index": 374,
                    "sent_index": 0,
                    "speaker": "PhD A",
                    "content": "as there {disfmarker} there are some {disfmarker} some problems in , when , in the channel , there {disfmarker} they {disfmarker} the the speaker doesn't {disfmarker} doesn't talk much or doesn't talk at all ."
                },
                {
                    "type": "CES",
                    "turn_index": 374,
                    "sent_index": 1,
                    "speaker": "PhD A",
                    "content": "Then , the , yeah , there are {disfmarker} there are some problems with {disfmarker} with {disfmarker} with n with normalization , and , then , uh , there the system doesn't work at all ."
                }
            ],
            [
                {
                    "type": "CES",
                    "turn_index": 376,
                    "sent_index": 1,
                    "speaker": "PhD A",
                    "content": "And , the thing is I {disfmarker} I , then the evaluation of {disfmarker} of the system is a little bit hard , as I don't have any references ."
                },
                {
                    "type": "PES",
                    "turn_index": 381,
                    "sent_index": 0,
                    "speaker": "PhD D",
                    "content": "Well won't you have that from their transcriptions ?"
                },
                {
                    "type": "PES",
                    "turn_index": 383,
                    "sent_index": 0,
                    "speaker": "Grad F",
                    "content": "No , cuz we need is really tight ."
                },
                {
                    "type": "CES",
                    "turn_index": 387,
                    "sent_index": 0,
                    "speaker": "Postdoc B",
                    "content": "I have thirty minutes that I 've more tightly transcribed with reference to individual channels ."
                }
            ],
            [
                {
                    "type": "CES",
                    "turn_index": 539,
                    "sent_index": 1,
                    "speaker": "Postdoc B",
                    "content": "it drifted into the afternoon , {comment} {vocalsound} uh , concerning this issue of , um , the , well there 's basically the issue of the interplay between the transcript format and the processing that , they need to do for , the SRI recognizer ."
                },
                {
                    "type": "CES",
                    "turn_index": 539,
                    "sent_index": 7,
                    "speaker": "Postdoc B",
                    "content": "And , then , I run it through , uh , the channelize program to get it into the multi - channel format , OK ."
                },
                {
                    "type": "CES",
                    "turn_index": 539,
                    "sent_index": 9,
                    "speaker": "Postdoc B",
                    "content": "And , um , {nonvocalsound} their recognizer would prefer that the units not be overly long ."
                },
                {
                    "type": "CES",
                    "turn_index": 539,
                    "sent_index": 10,
                    "speaker": "Postdoc B",
                    "content": "But it 's really an empirical question , whether the units we get at this point through , just that process I described might be sufficient for them ."
                }
            ],
            [
                {
                    "type": "CES",
                    "turn_index": 18,
                    "sent_index": 1,
                    "speaker": "Grad F",
                    "content": "OK well , the , w uh as you can see from the numbers on the digits we 're almost done ."
                },
                {
                    "type": "CES",
                    "turn_index": 21,
                    "sent_index": 0,
                    "speaker": "PhD D",
                    "content": "Test set , OK ."
                }
            ],
            [
                {
                    "type": "CES",
                    "turn_index": 18,
                    "sent_index": 7,
                    "speaker": "Grad F",
                    "content": "And so , once we 're {disfmarker} it 's done it would be very nice to train up a recognizer and actually start working with this data ."
                },
                {
                    "type": "CES",
                    "turn_index": 28,
                    "sent_index": 1,
                    "speaker": "Professor C",
                    "content": "and then , presumably , we should go to the distant mike , and it should do poorly ."
                },
                {
                    "type": "PES",
                    "turn_index": 30,
                    "sent_index": 0,
                    "speaker": "Professor C",
                    "content": "And then we should get really smart over the next year or two , and it {disfmarker} that should get better ."
                }
            ],
            [
                {
                    "type": "CES",
                    "turn_index": 57,
                    "sent_index": 4,
                    "speaker": "Professor C",
                    "content": "I think the best score was something like five percent , uh , error , per digit ."
                },
                {
                    "type": "PES",
                    "turn_index": 61,
                    "sent_index": 2,
                    "speaker": "Professor C",
                    "content": "So {disfmarker} So the {disfmarker} The point there , and this is uh car noise uh , uh things , but {disfmarker} but real {disfmarker} real situation ,"
                },
                {
                    "type": "CES",
                    "turn_index": 63,
                    "sent_index": 7,
                    "speaker": "Professor C",
                    "content": "uh that was with , many sites competing , and this was the very best score and so forth ,"
                },
                {
                    "type": "PES",
                    "turn_index": 65,
                    "sent_index": 3,
                    "speaker": "Professor C",
                    "content": "And so I {disfmarker} I think we 'd probably {disfmarker} the models would be better in some than in others ."
                },
                {
                    "type": "CES",
                    "turn_index": 65,
                    "sent_index": 4,
                    "speaker": "Professor C",
                    "content": "Um , so , uh . Anyway , just an indication once you get into this kind of realm even if you 're looking at connected digits it can be pretty hard ."
                }
            ],
            [
                {
                    "type": "CES",
                    "turn_index": 118,
                    "sent_index": 2,
                    "speaker": "Professor C",
                    "content": "One question I have that {disfmarker} that I mean , we wouldn't know the answer to now but might , do some guessing , but I was talking before about doing some model modeling of arti uh , uh , marking of articulatory , features , with overlap and so on ."
                },
                {
                    "type": "CES",
                    "turn_index": 120,
                    "sent_index": 2,
                    "speaker": "Professor C",
                    "content": "One thought might be to do this uh , on {disfmarker} on the digits , or some piece of the digits ."
                },
                {
                    "type": "CES",
                    "turn_index": 323,
                    "sent_index": 4,
                    "speaker": "Professor C",
                    "content": "So , I mean another way to look at this is to , is to , uh , do some stuff on Switchboard which has all this other , stuff to it ."
                }
            ],
            [
                {
                    "type": "CES",
                    "turn_index": 281,
                    "sent_index": 0,
                    "speaker": "PhD D",
                    "content": "Well cuz the yeah , and then also , if you did it on Switchboard , you would have , the full continuum of transcriptions ."
                },
                {
                    "type": "PES",
                    "turn_index": 283,
                    "sent_index": 0,
                    "speaker": "PhD D",
                    "content": "You 'd have it , from the lowest level , the ac acoustic features , then you 'd have the , you know , the phonetic level that Steve did ,"
                },
                {
                    "type": "CES",
                    "turn_index": 294,
                    "sent_index": 0,
                    "speaker": "PhD D",
                    "content": "But it {disfmarker} it might be good to do what Jane was saying uh , you know , seed it , with , guesses about what we think the features are , based on , you know , the phone or Steve 's transcriptions or something . to make it quicker ."
                },
                {
                    "type": "CES",
                    "turn_index": 301,
                    "sent_index": 3,
                    "speaker": "Professor C",
                    "content": "So I mean that 's probably the right way to go anyway , is to {disfmarker} is to start off with an automatic system with a pretty rich pronunciation dictionary that , that , um , you know , tries , to label it all ."
                },
                {
                    "type": "CES",
                    "turn_index": 302,
                    "sent_index": 2,
                    "speaker": "Postdoc B",
                    "content": "Or {pause} would we {disfmarker}"
                }
            ],
            [
                {
                    "type": "CES",
                    "turn_index": 4,
                    "sent_index": 0,
                    "speaker": "PhD A",
                    "content": "New version of the presegmentation ."
                },
                {
                    "type": "CES",
                    "turn_index": 360,
                    "sent_index": 0,
                    "speaker": "PhD A",
                    "content": "Uh , oh yeah , um , {vocalsound} I worked a little bit on the {disfmarker} on the presegmentation to {disfmarker} to get another version which does channel - specific , uh , speech - nonspeech detection ."
                },
                {
                    "type": "CES",
                    "turn_index": 362,
                    "sent_index": 1,
                    "speaker": "PhD A",
                    "content": "And , eh , I tested it on {disfmarker} on three or four meetings and it seems to work , well yeah , fairly well , I {disfmarker} I would say ."
                }
            ],
            [
                {
                    "type": "PES",
                    "turn_index": 360,
                    "sent_index": 0,
                    "speaker": "PhD A",
                    "content": "Uh , oh yeah , um , {vocalsound} I worked a little bit on the {disfmarker} on the presegmentation to {disfmarker} to get another version which does channel - specific , uh , speech - nonspeech detection ."
                },
                {
                    "type": "CES",
                    "turn_index": 360,
                    "sent_index": 3,
                    "speaker": "PhD A",
                    "content": "And to {disfmarker} to , mm , to , yeah , to normalize also loudness and {disfmarker} and modified loudness and things and that those special features actually are in my feature vector ."
                },
                {
                    "type": "CES",
                    "turn_index": 362,
                    "sent_index": 0,
                    "speaker": "PhD A",
                    "content": "And , and , therefore to be able to , uh , somewhat distinguish between foreground and background speech in {disfmarker} in the different {disfmarker} in {disfmarker} each channel ."
                }
            ],
            [
                {
                    "type": "CES",
                    "turn_index": 468,
                    "sent_index": 7,
                    "speaker": "PhD A",
                    "content": "Well {disfmarker} well what I want to do is to {disfmarker} to look into cross - correlations for {disfmarker} for removing those , false overlaps ."
                },
                {
                    "type": "PES",
                    "turn_index": 469,
                    "sent_index": 0,
                    "speaker": "Postdoc B",
                    "content": "Wonderful ."
                }
            ],
            [
                {
                    "type": "CES",
                    "turn_index": 543,
                    "sent_index": 0,
                    "speaker": "Postdoc B",
                    "content": "also we discussed some adaptational things ,"
                },
                {
                    "type": "CES",
                    "turn_index": 547,
                    "sent_index": 0,
                    "speaker": "Postdoc B",
                    "content": "uh {disfmarker} You know I hadn't , uh , incorporated , a convention explicitly to handle acronyms , for example ,"
                },
                {
                    "type": "CES",
                    "turn_index": 549,
                    "sent_index": 6,
                    "speaker": "Postdoc B",
                    "content": "And then , a similar conv uh , convention for numbers ."
                },
                {
                    "type": "CES",
                    "turn_index": 550,
                    "sent_index": 0,
                    "speaker": "PhD G",
                    "content": "Yeah we j we just needed a way to , strip , you know , all the comments , all the things th the {disfmarker} that linguist wants but the recognizer can't do anything with ."
                },
                {
                    "type": "CES",
                    "turn_index": 558,
                    "sent_index": 2,
                    "speaker": "PhD G",
                    "content": "So if they hear a breath and they don't know who breath it is it 's better to put it in that channel than to put it in the speaker 's channel"
                }
            ],
            [
                {
                    "type": "CES",
                    "turn_index": 560,
                    "sent_index": 4,
                    "speaker": "PhD G",
                    "content": "So {pause} when that 's , ready {disfmarker} you know , as soon as that 's ready , and as soon as the recognizer is here we can get , twelve hours of force - aligned and recognized data ."
                }
            ]
        ]
    },
    "qmsum": {
        "general_query_list": [
            {
                "query": "Summarize the meeting.",
                "tokenized_answer": [
                    "The group discussed the collection status for a set of connected digits recordings that are nearly complete and ready to be trained on a recognizer.",
                    "Anticipated results were discussed in reference to results obtained for other digits corpora, i.e. Aurora and TI-digits.",
                    "The group also considered the prospect of performing fine-grained acoustic-phonetic analyses on a subset of Meeting Recorder digits or Switchboard data.",
                    "Pre-segmentation manipulations that allow for the segmentation of channel-specific speech/non-speech portions of the signal and the distinction of foreground versus background speech were discussed.",
                    "Finally, speaker fe008 and fe016 reported on new efforts to adapt transcriptions to the needs of the SRI recognizer, including conventions for encoding acronyms, numbers, ambient noise, and unidentified inbreaths."
                ],
                "answer_sentence_index": [
                    [
                        0
                    ],
                    [
                        1
                    ],
                    [
                        2
                    ],
                    [
                        3
                    ],
                    [
                        4
                    ]
                ],
                "evidence": [
                    [
                        {
                            "type": "CES",
                            "turn_index": 2,
                            "sent_index": 0,
                            "speaker": "Grad F",
                            "content": "Um , so I wanted to discuss digits briefly , but that won't take too long ."
                        },
                        {
                            "type": "CES",
                            "turn_index": 18,
                            "sent_index": 1,
                            "speaker": "Grad F",
                            "content": "OK well , the , w uh as you can see from the numbers on the digits we 're almost done ."
                        },
                        {
                            "type": "CES",
                            "turn_index": 18,
                            "sent_index": 7,
                            "speaker": "Grad F",
                            "content": "And so , once we 're {disfmarker} it 's done it would be very nice to train up a recognizer and actually start working with this data ."
                        }
                    ],
                    [
                        {
                            "type": "CES",
                            "turn_index": 19,
                            "sent_index": 0,
                            "speaker": "PhD D",
                            "content": "So we 'll have a corpus that 's the size of TI - digits ?"
                        },
                        {
                            "type": "PES",
                            "turn_index": 20,
                            "sent_index": 1,
                            "speaker": "Grad F",
                            "content": "One particular test set of TI - digits ."
                        },
                        {
                            "type": "CES",
                            "turn_index": 57,
                            "sent_index": 1,
                            "speaker": "Professor C",
                            "content": "Yeah just by way of uh , uh , a uh , order of magnitude , uh , um , we 've been working with this Aurora , uh data set ."
                        },
                        {
                            "type": "CES",
                            "turn_index": 57,
                            "sent_index": 2,
                            "speaker": "Professor C",
                            "content": "And , uh , the best score , on the , nicest part of the data , that is , where you 've got training and test set that are basically the same kinds of noise and so forth , uh , is about ,"
                        },
                        {
                            "type": "CES",
                            "turn_index": 57,
                            "sent_index": 4,
                            "speaker": "Professor C",
                            "content": "I think the best score was something like five percent , uh , error , per digit ."
                        }
                    ],
                    [
                        {
                            "type": "PES",
                            "turn_index": 118,
                            "sent_index": 2,
                            "speaker": "Professor C",
                            "content": "One question I have that {disfmarker} that I mean , we wouldn't know the answer to now but might , do some guessing , but I was talking before about doing some model modeling of arti uh , uh , marking of articulatory , features , with overlap and so on ."
                        },
                        {
                            "type": "CES",
                            "turn_index": 120,
                            "sent_index": 1,
                            "speaker": "Professor C",
                            "content": "On some subset ."
                        },
                        {
                            "type": "CES",
                            "turn_index": 120,
                            "sent_index": 2,
                            "speaker": "Professor C",
                            "content": "One thought might be to do this uh , on {disfmarker} on the digits , or some piece of the digits ."
                        },
                        {
                            "type": "CES",
                            "turn_index": 323,
                            "sent_index": 4,
                            "speaker": "Professor C",
                            "content": "So , I mean another way to look at this is to , is to , uh , do some stuff on Switchboard which has all this other , stuff to it ."
                        },
                        {
                            "type": "PES",
                            "turn_index": 325,
                            "sent_index": 0,
                            "speaker": "Professor C",
                            "content": "And then , um , As we get , further down the road and we can do more things ahead of time , we can , do some of the same things to the meeting data ."
                        },
                        {
                            "type": "CES",
                            "turn_index": 331,
                            "sent_index": 0,
                            "speaker": "Postdoc B",
                            "content": "They 'd be able to do phonetic - level coding , or articulatory ."
                        }
                    ],
                    [
                        {
                            "type": "PES",
                            "turn_index": 359,
                            "sent_index": 0,
                            "speaker": "Professor C",
                            "content": "Uh , new version of , uh , presegmentation ?"
                        },
                        {
                            "type": "CES",
                            "turn_index": 360,
                            "sent_index": 0,
                            "speaker": "PhD A",
                            "content": "Uh , oh yeah , um , {vocalsound} I worked a little bit on the {disfmarker} on the presegmentation to {disfmarker} to get another version which does channel - specific , uh , speech - nonspeech detection ."
                        },
                        {
                            "type": "CES",
                            "turn_index": 362,
                            "sent_index": 0,
                            "speaker": "PhD A",
                            "content": "And , and , therefore to be able to , uh , somewhat distinguish between foreground and background speech in {disfmarker} in the different {disfmarker} in {disfmarker} each channel ."
                        }
                    ],
                    [
                        {
                            "type": "CES",
                            "turn_index": 539,
                            "sent_index": 1,
                            "speaker": "Postdoc B",
                            "content": "it drifted into the afternoon , {comment} {vocalsound} uh , concerning this issue of , um , the , well there 's basically the issue of the interplay between the transcript format and the processing that , they need to do for , the SRI recognizer ."
                        },
                        {
                            "type": "CES",
                            "turn_index": 543,
                            "sent_index": 0,
                            "speaker": "Postdoc B",
                            "content": "also we discussed some adaptational things ,"
                        },
                        {
                            "type": "CES",
                            "turn_index": 547,
                            "sent_index": 0,
                            "speaker": "Postdoc B",
                            "content": "uh {disfmarker} You know I hadn't , uh , incorporated , a convention explicitly to handle acronyms , for example ,"
                        },
                        {
                            "type": "CES",
                            "turn_index": 549,
                            "sent_index": 6,
                            "speaker": "Postdoc B",
                            "content": "And then , a similar conv uh , convention for numbers ."
                        },
                        {
                            "type": "PES",
                            "turn_index": 549,
                            "sent_index": 11,
                            "speaker": "Postdoc B",
                            "content": "Or a non - vocal sound like a doors door - slam , and that can be easily done with a , you know , just a {disfmarker} one little additional thing in the , in the general format ."
                        },
                        {
                            "type": "CES",
                            "turn_index": 558,
                            "sent_index": 2,
                            "speaker": "PhD G",
                            "content": "So if they hear a breath and they don't know who breath it is it 's better to put it in that channel than to put it in the speaker 's channel"
                        }
                    ]
                ]
            }
        ],
        "specific_query_list": [
            {
                "query": "Summarize what was said about the digits recordings",
                "tokenized_answer": [
                    "The group discussed the collection status for a set of connected digits recordings that are nearly complete and ready to be trained on a recognizer.",
                    "Anticipated results were discussed in reference to results obtained for other digits corpora, i.e. Aurora and TI-digits."
                ],
                "answer_sentence_index": [
                    [
                        0
                    ],
                    [
                        1
                    ]
                ],
                "evidence": [
                    [
                        {
                            "type": "CES",
                            "turn_index": 2,
                            "sent_index": 0,
                            "speaker": "Grad F",
                            "content": "Um , so I wanted to discuss digits briefly , but that won't take too long ."
                        },
                        {
                            "type": "CES",
                            "turn_index": 18,
                            "sent_index": 1,
                            "speaker": "Grad F",
                            "content": "OK well , the , w uh as you can see from the numbers on the digits we 're almost done ."
                        },
                        {
                            "type": "CES",
                            "turn_index": 18,
                            "sent_index": 7,
                            "speaker": "Grad F",
                            "content": "And so , once we 're {disfmarker} it 's done it would be very nice to train up a recognizer and actually start working with this data ."
                        }
                    ],
                    [
                        {
                            "type": "CES",
                            "turn_index": 19,
                            "sent_index": 0,
                            "speaker": "PhD D",
                            "content": "So we 'll have a corpus that 's the size of TI - digits ?"
                        },
                        {
                            "type": "PES",
                            "turn_index": 20,
                            "sent_index": 1,
                            "speaker": "Grad F",
                            "content": "One particular test set of TI - digits ."
                        },
                        {
                            "type": "CES",
                            "turn_index": 57,
                            "sent_index": 1,
                            "speaker": "Professor C",
                            "content": "Yeah just by way of uh , uh , a uh , order of magnitude , uh , um , we 've been working with this Aurora , uh data set ."
                        },
                        {
                            "type": "CES",
                            "turn_index": 57,
                            "sent_index": 2,
                            "speaker": "Professor C",
                            "content": "And , uh , the best score , on the , nicest part of the data , that is , where you 've got training and test set that are basically the same kinds of noise and so forth , uh , is about ,"
                        },
                        {
                            "type": "CES",
                            "turn_index": 57,
                            "sent_index": 4,
                            "speaker": "Professor C",
                            "content": "I think the best score was something like five percent , uh , error , per digit ."
                        }
                    ]
                ]
            },
            {
                "query": "What was said about the transcriber pool?",
                "tokenized_answer": [
                    "decision was also made to delegate transcribers with the task of labelling a subset of digits or Switchboard data for fine-grained acoustic-phonetic features.",
                    "Speaker fe008 will run selected Meeting Recorder data through channelize and determine whether the resulting units are of a sufficient length."
                ],
                "answer_sentence_index": [
                    [
                        0
                    ],
                    [
                        1
                    ]
                ],
                "evidence": [
                    [
                        {
                            "type": "CES",
                            "turn_index": 135,
                            "sent_index": 1,
                            "speaker": "Professor C",
                            "content": "So , may maybe the thing will be do {disfmarker} to take some very small subset , I mean not have a big , program , but take a small set , uh , subset of the conversational speech and a small subset of the digits ,"
                        },
                        {
                            "type": "CES",
                            "turn_index": 142,
                            "sent_index": 0,
                            "speaker": "PhD D",
                            "content": "Hafta think about , the particular acoustic features to mark , too , because , I mean , some things , they wouldn't be able to mark , like , uh , you know , uh , tense lax ."
                        },
                        {
                            "type": "CES",
                            "turn_index": 222,
                            "sent_index": 0,
                            "speaker": "PhD D",
                            "content": "So it would be {disfmarker} it would be great if we had , either these kind of , labelings on , the same portion of Switchboard that Steve marked , or , Steve 's type markings on this data , with these ."
                        },
                        {
                            "type": "CES",
                            "turn_index": 271,
                            "sent_index": 0,
                            "speaker": "PhD D",
                            "content": "Well , you know , um {disfmarker} I mean if we 're talking about , having the , annotators annotate these kinds of features , it seems like ,"
                        },
                        {
                            "type": "PES",
                            "turn_index": 291,
                            "sent_index": 1,
                            "speaker": "Professor C",
                            "content": "So I mean i we 'll see wha how much we can , uh , get the people to do , and how much money we 'll have and all this sort of thing ,"
                        },
                        {
                            "type": "CES",
                            "turn_index": 323,
                            "sent_index": 4,
                            "speaker": "Professor C",
                            "content": "So , I mean another way to look at this is to , is to , uh , do some stuff on Switchboard which has all this other , stuff to it ."
                        }
                    ],
                    [
                        {
                            "type": "PES",
                            "turn_index": 539,
                            "sent_index": 9,
                            "speaker": "Postdoc B",
                            "content": "And , um , {nonvocalsound} their recognizer would prefer that the units not be overly long ."
                        },
                        {
                            "type": "CES",
                            "turn_index": 539,
                            "sent_index": 11,
                            "speaker": "Postdoc B",
                            "content": "So , as a first pass through , a first chance without having to do a lot of hand - editing , what we 're gonna do , is , I 'll run it through channelize , give them those data after I 've done the editing process and be sure it 's clean ."
                        },
                        {
                            "type": "CES",
                            "turn_index": 541,
                            "sent_index": 0,
                            "speaker": "Postdoc B",
                            "content": "And then we 'll see if the units that we 're getting , uh , with the {disfmarker} at that level , are sufficient ."
                        }
                    ]
                ]
            },
            {
                "query": "What did the group say about acoustic-phonetic analyses?",
                "tokenized_answer": [
                    "The group also considered the prospect of performing fine-grained acoustic-phonetic analyses on a subset of Meeting Recorder digits or Switchboard data.",
                    "Pre-segmentation manipulations that allow for the segmentation of channel-specific speech/non-speech portions of the signal and the distinction of foreground versus background speech were discussed."
                ],
                "answer_sentence_index": [
                    [
                        0
                    ],
                    [
                        1
                    ]
                ],
                "evidence": [
                    [
                        {
                            "type": "PES",
                            "turn_index": 118,
                            "sent_index": 2,
                            "speaker": "Professor C",
                            "content": "One question I have that {disfmarker} that I mean , we wouldn't know the answer to now but might , do some guessing , but I was talking before about doing some model modeling of arti uh , uh , marking of articulatory , features , with overlap and so on ."
                        },
                        {
                            "type": "CES",
                            "turn_index": 120,
                            "sent_index": 1,
                            "speaker": "Professor C",
                            "content": "On some subset ."
                        },
                        {
                            "type": "CES",
                            "turn_index": 120,
                            "sent_index": 2,
                            "speaker": "Professor C",
                            "content": "One thought might be to do this uh , on {disfmarker} on the digits , or some piece of the digits ."
                        },
                        {
                            "type": "CES",
                            "turn_index": 323,
                            "sent_index": 4,
                            "speaker": "Professor C",
                            "content": "So , I mean another way to look at this is to , is to , uh , do some stuff on Switchboard which has all this other , stuff to it ."
                        },
                        {
                            "type": "PES",
                            "turn_index": 325,
                            "sent_index": 0,
                            "speaker": "Professor C",
                            "content": "And then , um , As we get , further down the road and we can do more things ahead of time , we can , do some of the same things to the meeting data ."
                        },
                        {
                            "type": "CES",
                            "turn_index": 331,
                            "sent_index": 0,
                            "speaker": "Postdoc B",
                            "content": "They 'd be able to do phonetic - level coding , or articulatory ."
                        }
                    ],
                    [
                        {
                            "type": "PES",
                            "turn_index": 359,
                            "sent_index": 0,
                            "speaker": "Professor C",
                            "content": "Uh , new version of , uh , presegmentation ?"
                        },
                        {
                            "type": "CES",
                            "turn_index": 360,
                            "sent_index": 0,
                            "speaker": "PhD A",
                            "content": "Uh , oh yeah , um , {vocalsound} I worked a little bit on the {disfmarker} on the presegmentation to {disfmarker} to get another version which does channel - specific , uh , speech - nonspeech detection ."
                        },
                        {
                            "type": "CES",
                            "turn_index": 362,
                            "sent_index": 0,
                            "speaker": "PhD A",
                            "content": "And , and , therefore to be able to , uh , somewhat distinguish between foreground and background speech in {disfmarker} in the different {disfmarker} in {disfmarker} each channel ."
                        }
                    ]
                ]
            },
            {
                "query": "What approaches were considered for the analysis?",
                "tokenized_answer": [
                    "The group discussed the prospect of performing fine-grained acoustic-phonetic analyses on a subset of digits or Switchboard data.",
                    "It was suggested that prior to the use of data-driven methods, knowledge-driven approaches should be used to 'seed' the data with sub-phonemic features, either manually, or using a rich pronunciation dictionary.",
                    "A new version of the pre-segmentation tool that segments channel-specific speech/non-speech portions of the signal has been developed and tested."
                ],
                "answer_sentence_index": [
                    [
                        0
                    ],
                    [
                        1
                    ],
                    [
                        2
                    ]
                ],
                "evidence": [
                    [
                        {
                            "type": "CES",
                            "turn_index": 120,
                            "sent_index": 1,
                            "speaker": "Professor C",
                            "content": "On some subset ."
                        },
                        {
                            "type": "CES",
                            "turn_index": 120,
                            "sent_index": 2,
                            "speaker": "Professor C",
                            "content": "One thought might be to do this uh , on {disfmarker} on the digits , or some piece of the digits ."
                        },
                        {
                            "type": "CES",
                            "turn_index": 323,
                            "sent_index": 4,
                            "speaker": "Professor C",
                            "content": "So , I mean another way to look at this is to , is to , uh , do some stuff on Switchboard which has all this other , stuff to it ."
                        },
                        {
                            "type": "PES",
                            "turn_index": 325,
                            "sent_index": 0,
                            "speaker": "Professor C",
                            "content": "And then , um , As we get , further down the road and we can do more things ahead of time , we can , do some of the same things to the meeting data ."
                        },
                        {
                            "type": "CES",
                            "turn_index": 331,
                            "sent_index": 0,
                            "speaker": "Postdoc B",
                            "content": "They 'd be able to do phonetic - level coding , or articulatory ."
                        }
                    ],
                    [
                        {
                            "type": "CES",
                            "turn_index": 281,
                            "sent_index": 0,
                            "speaker": "PhD D",
                            "content": "Well cuz the yeah , and then also , if you did it on Switchboard , you would have , the full continuum of transcriptions ."
                        },
                        {
                            "type": "PES",
                            "turn_index": 283,
                            "sent_index": 0,
                            "speaker": "PhD D",
                            "content": "You 'd have it , from the lowest level , the ac acoustic features , then you 'd have the , you know , the phonetic level that Steve did ,"
                        },
                        {
                            "type": "CES",
                            "turn_index": 294,
                            "sent_index": 0,
                            "speaker": "PhD D",
                            "content": "But it {disfmarker} it might be good to do what Jane was saying uh , you know , seed it , with , guesses about what we think the features are , based on , you know , the phone or Steve 's transcriptions or something . to make it quicker ."
                        },
                        {
                            "type": "CES",
                            "turn_index": 301,
                            "sent_index": 3,
                            "speaker": "Professor C",
                            "content": "So I mean that 's probably the right way to go anyway , is to {disfmarker} is to start off with an automatic system with a pretty rich pronunciation dictionary that , that , um , you know , tries , to label it all ."
                        },
                        {
                            "type": "CES",
                            "turn_index": 302,
                            "sent_index": 2,
                            "speaker": "Postdoc B",
                            "content": "Or {pause} would we {disfmarker}"
                        }
                    ],
                    [
                        {
                            "type": "CES",
                            "turn_index": 4,
                            "sent_index": 0,
                            "speaker": "PhD A",
                            "content": "New version of the presegmentation ."
                        },
                        {
                            "type": "CES",
                            "turn_index": 360,
                            "sent_index": 0,
                            "speaker": "PhD A",
                            "content": "Uh , oh yeah , um , {vocalsound} I worked a little bit on the {disfmarker} on the presegmentation to {disfmarker} to get another version which does channel - specific , uh , speech - nonspeech detection ."
                        },
                        {
                            "type": "CES",
                            "turn_index": 362,
                            "sent_index": 1,
                            "speaker": "PhD A",
                            "content": "And , eh , I tested it on {disfmarker} on three or four meetings and it seems to work , well yeah , fairly well , I {disfmarker} I would say ."
                        }
                    ]
                ]
            }
        ]
    }
}